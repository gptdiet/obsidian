
[Polycoder](https://github.com/VHellendoorn/Code-LMs "https://github.com/VHellendoorn/Code-LMs") is an open source alternative to OpenAI’s Codex. Developed by the researchers at Carnegie Mellon University, the model is based on OpenAI’s GPT-2, which is trained on a 249 GB codebase written in 12 programming languages. According to PolyCoder's authors, the program is capable of writing C with greater accuracy than any other model, including Codex.

While most of the code generators are not open source, Polycoder is one of the first open source code generation models.

via Forbes.com